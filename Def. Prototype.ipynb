{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interesting-lemon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import ray\\nray.init(plasma_directory=\"/workspaces/96273/temp\")\\nimport modin.pandas as pd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import metrics\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\"\"\"import ray\n",
    "ray.init(plasma_directory=\"/workspaces/96273/temp\")\n",
    "import modin.pandas as pd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "  assert tf.config.experimental.get_memory_growth(physical_devices[0])\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-aberdeen",
   "metadata": {},
   "source": [
    "With this function I try to safe memory. It avoids allocate all GPUs and all memory. (graphic processing unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVggFaceModel():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "    \n",
    "    return vgg_face_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mounted-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadVggFaceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reliable-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-montreal",
   "metadata": {},
   "source": [
    "Here i construct the VGG face model in Keras. And than uploaded a pre-trained model from VGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "billion-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-carnival",
   "metadata": {},
   "source": [
    "Here I insert the open-cv face detection module "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-indonesian",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "social-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('imdb_crop/imdb.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-villa",
   "metadata": {},
   "source": [
    "Uploaded a dataset with faces from IMDB with faces of different actors male and female. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "executive-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\", \"celeb_names\", \"celeb_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emotional-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = mat['imdb'][0][0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "corresponding-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = range(0,instances), columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "republican-convention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460723, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "running-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .  dob :  [693726 693726 693726 ... 726831 726831 726831]\n",
      "1 .  photo_taken :  [1968 1970 1968 ... 2011 2011 2011]\n",
      "2 .  full_path :  [array(['01/nm0000001_rm124825600_1899-5-10_1968.jpg'], dtype='<U43')\n",
      " array(['01/nm0000001_rm3343756032_1899-5-10_1970.jpg'], dtype='<U44')\n",
      " array(['01/nm0000001_rm577153792_1899-5-10_1968.jpg'], dtype='<U43') ...\n",
      " array(['08/nm3994408_rm926592512_1989-12-29_2011.jpg'], dtype='<U44')\n",
      " array(['08/nm3994408_rm943369728_1989-12-29_2011.jpg'], dtype='<U44')\n",
      " array(['08/nm3994408_rm976924160_1989-12-29_2011.jpg'], dtype='<U44')]\n",
      "3 .  gender :  [1. 1. 1. ... 0. 0. 0.]\n",
      "4 .  name :  [array(['Fred Astaire'], dtype='<U12')\n",
      " array(['Fred Astaire'], dtype='<U12')\n",
      " array(['Fred Astaire'], dtype='<U12') ...\n",
      " array(['Jane Levy'], dtype='<U9') array(['Jane Levy'], dtype='<U9')\n",
      " array(['Jane Levy'], dtype='<U9')]\n",
      "5 .  face_location :  [array([[1072.926,  161.838, 1214.784,  303.696]])\n",
      " array([[477.184, 100.352, 622.592, 245.76 ]])\n",
      " array([[114.96964309, 114.96964309, 451.68657236, 451.68657236]]) ...\n",
      " array([[  1,   1, 453, 640]], dtype=uint16)\n",
      " array([[144.75225472, 126.76472288, 305.78804127, 287.80050943]])\n",
      " array([[457.524,  41.748, 518.016, 102.24 ]])]\n",
      "6 .  face_score :  [1.45969291 2.5431976  3.45557949 ...       -inf 4.45072452 2.13350269]\n",
      "7 .  second_face_score :  [1.11897336 1.85200773 2.98566022 ...        nan        nan        nan]\n",
      "8 .  celeb_names :  [array([\"'Lee' George Quinones\"], dtype='<U21')\n",
      " array([\"'Weird Al' Yankovic\"], dtype='<U19')\n",
      " array(['2 Chainz'], dtype='<U8') ...\n",
      " array(['Éric Caravaca'], dtype='<U13')\n",
      " array(['Ólafur Darri Ólafsson'], dtype='<U21')\n",
      " array(['Óscar Jaenada'], dtype='<U13')]\n",
      "9 .  celeb_id :  [6488 6488 6488 ... 8410 8410 8410]\n"
     ]
    }
   ],
   "source": [
    "for i in mat:\n",
    "    if i == \"imdb\":\n",
    "        current_array = mat[i][0][0]\n",
    "        for j in range(len(current_array)):\n",
    "            print(j,\". \",columns[j],\": \",current_array[j][0])\n",
    "            df[columns[j]] = pd.DataFrame(current_array[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "macro-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>celeb_names</th>\n",
       "      <th>celeb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm124825600_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1072.926, 161.838, 1214.7839999999999, 303.6...</td>\n",
       "      <td>1.459693</td>\n",
       "      <td>1.118973</td>\n",
       "      <td>['Lee' George Quinones]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693726</td>\n",
       "      <td>1970</td>\n",
       "      <td>[01/nm0000001_rm3343756032_1899-5-10_1970.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[477.184, 100.352, 622.592, 245.76]]</td>\n",
       "      <td>2.543198</td>\n",
       "      <td>1.852008</td>\n",
       "      <td>['Weird Al' Yankovic]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm577153792_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[114.96964308962852, 114.96964308962852, 451....</td>\n",
       "      <td>3.455579</td>\n",
       "      <td>2.985660</td>\n",
       "      <td>[2 Chainz]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm946909184_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[622.8855056426588, 424.21750383700805, 844.3...</td>\n",
       "      <td>1.872117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[50 Cent]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm980463616_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1013.8590023603723, 233.8820422075853, 1201....</td>\n",
       "      <td>1.158766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[A Martinez]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                                       full_path  \\\n",
       "0  693726         1968   [01/nm0000001_rm124825600_1899-5-10_1968.jpg]   \n",
       "1  693726         1970  [01/nm0000001_rm3343756032_1899-5-10_1970.jpg]   \n",
       "2  693726         1968   [01/nm0000001_rm577153792_1899-5-10_1968.jpg]   \n",
       "3  693726         1968   [01/nm0000001_rm946909184_1899-5-10_1968.jpg]   \n",
       "4  693726         1968   [01/nm0000001_rm980463616_1899-5-10_1968.jpg]   \n",
       "\n",
       "   gender            name                                      face_location  \\\n",
       "0     1.0  [Fred Astaire]  [[1072.926, 161.838, 1214.7839999999999, 303.6...   \n",
       "1     1.0  [Fred Astaire]              [[477.184, 100.352, 622.592, 245.76]]   \n",
       "2     1.0  [Fred Astaire]  [[114.96964308962852, 114.96964308962852, 451....   \n",
       "3     1.0  [Fred Astaire]  [[622.8855056426588, 424.21750383700805, 844.3...   \n",
       "4     1.0  [Fred Astaire]  [[1013.8590023603723, 233.8820422075853, 1201....   \n",
       "\n",
       "   face_score  second_face_score              celeb_names  celeb_id  \n",
       "0    1.459693           1.118973  ['Lee' George Quinones]      6488  \n",
       "1    2.543198           1.852008    ['Weird Al' Yankovic]      6488  \n",
       "2    3.455579           2.985660               [2 Chainz]      6488  \n",
       "3    1.872117                NaN                [50 Cent]      6488  \n",
       "4    1.158766                NaN             [A Martinez]      6488  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "broadband-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pictures does not include face\n",
    "df = df[df['face_score'] != -np.inf]\n",
    "\n",
    "#some pictures include more than one face, remove them\n",
    "df = df[df['second_face_score'].isna()]\n",
    "\n",
    "#check threshold\n",
    "df = df[df['face_score'] >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "painful-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95234, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "requested-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNames(name):\n",
    "    return name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conservative-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['celebrity_name'] = df['name'].apply(extractNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brazilian-rapid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95234, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-public",
   "metadata": {},
   "source": [
    "Datasets can have useless pictuers. Think about not included faces or multiple faces or ambigous faces. Above I discard these faces. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-delivery",
   "metadata": {},
   "source": [
    "# Load data set images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-practice",
   "metadata": {},
   "source": [
    "The Data set includes the physical location of the image. This needs to be loaded as pixel values. The images are being read with OpenCV because it can additionally crop faces with this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "framed-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePixels(image_path):\n",
    "    return cv2.imread(\"imdb_crop/%s\" % image_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "df['pixels'] = df['full_path'].apply(getImagePixels)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"this block completed in \",toc-tic,\" seconds...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-academy",
   "metadata": {},
   "source": [
    "### During this step Jupyter notebook shuts down and I get a notification that my memory is full. I tried everything from buying a harddrive to downgrading and upgrading tensorflow, keras, python etc. I just wasnt able to get past this point. This is why I am not sure if the rest of the code works. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-england",
   "metadata": {},
   "source": [
    "# Represent images as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-litigation",
   "metadata": {},
   "source": [
    "The items in the data set has to represent as vectors. A vector is similar to an Array, it holds multiple number values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFaceRepresentation(img):\n",
    "    detected_face = img\n",
    "    \n",
    "    try: \n",
    "        detected_face = cv2.resize(detected_face, (224, 224))\n",
    "        \n",
    "        #normalize detected face in scale of -1, +1\n",
    "\n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 127.5\n",
    "        img_pixels -= 1\n",
    "        \n",
    "        representation = model.predict(img_pixels)[0,:]\n",
    "    except:\n",
    "        representation = None\n",
    "        \n",
    "    return representation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "df['face_vector_raw'] = df['pixels'].apply(findFaceRepresentation) #vector for raw image\n",
    "toc = time.time()\n",
    "\n",
    "print(\"this block completed in \",toc-tic,\" seconds...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-court",
   "metadata": {},
   "source": [
    "# Load Your Photo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-auditor",
   "metadata": {},
   "source": [
    "Here we look at the representation of the image as vector. The dataset exists of cropped faces with a 40% margin. That’s why, the picture should be adjusted to these measurements. It should detect a face in the image and add a margin. As mentioned before the OpenCV’s haarcascade classifier is used to detect faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"IMG_0471 kopie.jpg\") \n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    \n",
    "    try:\n",
    "        margin = 10\n",
    "        margin_x = int((w * margin)/100); margin_y = int((h * margin)/100)\n",
    "        detected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "    except:\n",
    "        print(\"detected face has no margin\")\n",
    "    \n",
    "    detected_face = cv2.resize(detected_face, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixels = image.img_to_array(detected_face)\n",
    "img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "img_pixels /= 127.5\n",
    "img_pixels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "yourself_representation = model.predict(img_pixels)[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-dallas",
   "metadata": {},
   "source": [
    "# Finding Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-vacation",
   "metadata": {},
   "source": [
    "Both the input image and the images in imdb data set are represented as 2622 dimensional vectors. This is used to find similarities witch each image vector in imdb data set and the input image vector. As you can see the distance is 1 – similarity. The less distance score (0 is the best), the more similarity exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(source_representation, test_representation=yourself_representation):\n",
    "    try:\n",
    "        a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "        b = np.sum(np.multiply(source_representation, source_representation))\n",
    "        c = np.sum(np.multiply(test_representation, test_representation))\n",
    "        return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "    except:\n",
    "        return 10 #assigned a large value. similar faces will have small value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity'] = df['face_vector_raw'].apply(findCosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['similarity'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x = df.iloc[0]['pixels'].reshape(224, 224, 3)/255\n",
    "plt.imshow(x)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-segment",
   "metadata": {},
   "source": [
    "Here I sort the data frame by disntance value and focus on the top 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for i in range(0, 7):\n",
    "        instance = df.iloc[i]\n",
    "        name = instance['celebrity_name']\n",
    "        similarity = instance['similarity']\n",
    "        \n",
    "        img = instance['pixels']\n",
    "        full_path = instance['full_path'][0]\n",
    "        img = cv2.imread(\"imdb_crop/%s\" % full_path)\n",
    "        \n",
    "        print(i,\".\",name,\" (\",similarity,\") - \",full_path)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.drop_duplicates(subset =\"celebrity_name\")\n",
    "pivot_df = pivot_df[pivot_df['photo_taken'] >= 2000]\n",
    "\n",
    "#0: woman, 1: man. \n",
    "pivot_df = pivot_df[pivot_df['gender'] == 1]\n",
    "\n",
    "pivot_df = pivot_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "    instance = pivot_df.iloc[i]\n",
    "    name = instance['celebrity_name']\n",
    "    similarity = instance['similarity']\n",
    "    \n",
    "    similarity = (1 - similarity)*100\n",
    "    \n",
    "    full_path = instance['full_path'][0]\n",
    "    img = cv2.imread(\"imdb_crop/%s\" % full_path)\n",
    "    \n",
    "    print(name,\" (\",similarity,\"%) - \",full_path)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
